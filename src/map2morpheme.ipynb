{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Lets see what we can do with a wordmap (plot, noise reduction and possibly partitioning into morphemes?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import wordmapper\n",
    "import text_utilities as tu\n",
    "import numpy as np # arrays\n",
    "import scipy.stats as stats # arithmetics\n",
    "import matplotlib.pyplot as pp # plotting\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_131197/2497575430.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mt\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtargets\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\",\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m     \u001B[0mwm\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mwordmapper\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mWordMapper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcounted_corpus\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m     \u001B[0mmt\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mwordmapper\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mMapToken\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mwm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwordmap\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmetrics\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m     \u001B[0mwm_mt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtoken\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwordmap\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: __init__() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "pc = tu.PosCorpus('../data/experiment/verbs/joined/')\n",
    "\n",
    "targets = \"beschissen,stehen,anschauen,viertelt,verunglimpfst\"\n",
    "wm_mt = []\n",
    "for t in targets.split(\",\"):\n",
    "    wm = wordmapper.WordMapper(t, pc.counted_corpus)\n",
    "    mt = wordmapper.MapToken(t, wm.wordmap, pc.metrics)\n",
    "    wm_mt.append((mt.token, mt.wordmap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_targets(maptokens, absolute=False, zscore=False, med=False, std=False, mean=False, mmmix=False, zeroline=False, derive=False):\n",
    "    for (target, wm) in maptokens:\n",
    "\n",
    "        arr = np.array(wm)\n",
    "        wm_med = np.array([np.median(wm) for i in wm])\n",
    "        wm_mea = np.array([np.mean(wm) for i in wm])\n",
    "        wm_std = np.array([np.std(wm) for i in wm])\n",
    "        wm_mix = [(x+y)/2 for x, y, in zip(wm_mea, wm_med)]\n",
    "        wm_zero = [0 for i in range(len(arr))]\n",
    "        wm_derive = wm_derive = np.array(stats.zscore(tu.derive_wordmap(wm)))\n",
    "        wm_zscore = np.array(stats.zscore(arr))\n",
    "\n",
    "        if absolute:\n",
    "            pp.plot(range(len(arr)), arr)\n",
    "        if med:\n",
    "            pp.plot(range(len(arr)), wm_med)\n",
    "        if mean:\n",
    "            pp.plot(range(len(arr)), wm_mea)\n",
    "        if std:\n",
    "            pp.plot(range(len(arr)), wm_std)\n",
    "        if mmmix:\n",
    "            pp.plot(range(len(arr)), wm_mix)\n",
    "        if zscore:\n",
    "            pp.plot(range(len(arr)), wm_zscore)\n",
    "        if zeroline:\n",
    "            pp.plot(range(len(arr)), wm_zero)\n",
    "        if derive:\n",
    "            pp.plot(range(len(arr)), wm_derive)\n",
    "\n",
    "\n",
    "    pp.xlabel('Character positions')\n",
    "    pp.ylabel('Frequency')\n",
    "    pp.xticks(np.arange(stop=len(arr),step=1), labels=list(target))\n",
    "    pp.savefig(\"/home/gnom/Pictures/wordmaps/zscore\" + target + \".png\")\n",
    "    pp.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for (x,y) in wm_mt:\n",
    "    plot_targets(\n",
    "        maptokens=[(x,y)],\n",
    "        absolute=False,\n",
    "        med=  False,\n",
    "        mmmix=False,\n",
    "        mean= False,\n",
    "        zscore=  True,\n",
    "        zeroline=True,\n",
    "        derive=  True\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def signaltonoise(a, axis=0, ddof=0):\n",
    "    \"\"\"\n",
    "    The signal-to-noise ratio of the input data.\n",
    "    Returns the signal-to-noise ratio of `a`, here defined as the mean\n",
    "    divided by the standard deviation.\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : array_like\n",
    "        An array_like object containing the sample data.\n",
    "    axis : int or None, optional\n",
    "        Axis along which to operate. Default is 0. If None, compute over\n",
    "        the whole array `a`.\n",
    "    ddof : int, optional\n",
    "        Degrees of freedom correction for standard deviation. Default is 0.\n",
    "    Returns\n",
    "    -------\n",
    "    s2n : ndarray\n",
    "        The mean to standard deviation ratio(s) along `axis`, or 0 where the\n",
    "        standard deviation is 0.\n",
    "    \"\"\"\n",
    "    a = np.asanyarray(a)\n",
    "    m = a.mean(axis)\n",
    "    sd = a.std(axis=axis, ddof=ddof)\n",
    "    return np.where(sd == 0, 0, m/sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6054367328205298\n"
     ]
    }
   ],
   "source": [
    "print(signaltonoise(wordmap1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "S = np.fft.fft(mt.wordmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "t = np.arange(8)\n",
    "#s = np.sin(0.15*2*np.pi*t)\n",
    "\n",
    "S_mag = np.abs(S)\n",
    "S_phase = np.angle(S)\n",
    "pp.plot(t,S_mag,'.-')\n",
    "pp.plot(t,S_phase,'.-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "Fs = 1 # Hz\n",
    "N = 8 # number of points to simulate, and our FFT size\n",
    "\n",
    "t = np.arange(N) # because our sample rate is 1 Hz\n",
    "\n",
    "S = np.fft.fftshift(np.fft.fft(mt.wordmap))\n",
    "S_mag = np.abs(S)\n",
    "S_phase = np.angle(S)\n",
    "f = np.arange(Fs/-2, Fs/2, Fs/N)\n",
    "pp.figure(0)\n",
    "pp.plot(f, S_mag,'.-')\n",
    "pp.figure(1)\n",
    "pp.plot(f, S_phase,'.-')\n",
    "pp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28675/28675 [4:21:32<00:00,  1.83it/s]  \n",
      "100%|██████████| 24964/24964 [2:55:31<00:00,  2.37it/s]  \n",
      "100%|██████████| 14169/14169 [2:11:32<00:00,  1.80it/s] \n",
      "100%|██████████| 4257/4257 [40:06<00:00,  1.77it/s]\n",
      "100%|██████████| 5008/5008 [35:26<00:00,  2.35it/s]\n",
      "100%|██████████| 974/974 [09:30<00:00,  1.71it/s]\n",
      "100%|██████████| 182/182 [01:50<00:00,  1.65it/s]\n",
      "100%|██████████| 32/32 [00:19<00:00,  1.61it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm as tq\n",
    "\n",
    "lex_morphemes = []\n",
    "fun_morphemes = []\n",
    "\n",
    "\n",
    "for k in pc.counted_corpus:\n",
    "    for v in tq(pc.counted_corpus[k]):\n",
    "        wm = wordmapper.WordMapper(v, pc.counted_corpus)\n",
    "        mt = wordmapper.MapToken(v, wm.wordmap)\n",
    "        lex_morphemes.append(mt.stem)\n",
    "        fun_morphemes.extend(mt.affix)\n",
    "\n",
    "#with open(\"../new_tokenizer/lex_vocab.txt\", encoding=\"utf8\", mode=\"w\") as lv:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not generator",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_131197/1039751851.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mwith\u001B[0m \u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"../new_tokenizer/lex_vocab.txt\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mencoding\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"utf8\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"w\"\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mlv\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m     \u001B[0mlv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwrite\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ms\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m\"\\n\"\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0ms\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlex_morphemes\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m     \u001B[0mlv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mfun_morphemes_set\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: write() argument must be str, not generator"
     ]
    }
   ],
   "source": [
    "with open(\"../new_tokenizer/lex_vocab.txt\", encoding=\"utf8\", mode=\"w\") as lv:\n",
    "    lv.write(s + \"\\n\" for s in set(lex_morphemes))\n",
    "    lv.close()\n",
    "\n",
    "fun_morphemes_set = set()\n",
    "for affixes in set(fun_morphemes):\n",
    "    for a in affixes:\n",
    "        fun_morphemes_set.update(a)\n",
    "\n",
    "with open(\"../new_tokenizer/fun_vocab.txt\", encoding=\"utf8\", mode=\"w\") as fv:\n",
    "    fv.write(s + \"\\n\" for s in set(fun_morphemes_set))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "outputs": [],
   "source": [
    "lex_morphemes_set = set(lex_morphemes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [],
   "source": [
    "def zip_wordmap(t: str, wm: list):\n",
    "    \"t = target string, wm = boolean wordmap.\"\n",
    "    stem = \"\".join([c for b, c in zip(wm, t) if b])\n",
    "    return stem, t.partition(stem)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('einandergeschlag', ('über', 'einandergeschlag', 'en')) ['über', 'en']\n"
     ]
    }
   ],
   "source": [
    "wm = wordmapper.WordMapper(\"übereinandergeschlagen\", pc.counted_corpus)\n",
    "mt = wordmapper.MapToken(wm.target, wm.wordmap)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "outputs": [],
   "source": [
    "morfs = []\n",
    "morfs.extend(mt.affix)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [],
   "source": [
    "with open(\"../new_tokenizer/fun_vocab.txt\", encoding=\"utf8\", mode=\"w\") as fv:\n",
    "    fv.write(\"\".join([s + \"\\n\" for s in set(morfs)]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "outputs": [
    {
     "data": {
      "text/plain": "['über', 'en']"
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "6b0d22e4e1c79272fa4d01070caf2162d45623480f744f42b9210d65f18de715"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
