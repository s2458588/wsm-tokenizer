{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import text_utilities as tu\n",
    "import regex as rex\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys([3, 1, 2, 4, 5, 6, 7, 8])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pc = tu.PosCorpus('../data/experiment/verbs')\n",
    "pc.counted_corpus.keys()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "class WordMapper:\n",
    "    \"\"\"Generates a Wordmap for a target token, comparing it to its POS-members in a dict sorted by syllables\"\"\"\n",
    "    def __init__(self, target: str, tokenset: dict, clean=True, pattern='([^^1][0*1*]+[^$1])'):\n",
    "        self.target = target\n",
    "        self.tokenset = tokenset\n",
    "        self.syllables = tu.count_syllables(target)\n",
    "        self.maps = self.stack_maps(target, tokenset, self.syllables)\n",
    "        self.pattern = pattern\n",
    "        self.clean_maps = None\n",
    "        if clean:\n",
    "            self.filter_map_noise(self.maps, self.pattern)\n",
    "            self.wordmap = self.sum_map_stack(self.clean_maps)\n",
    "        else:\n",
    "            self.wordmap = self.sum_map_stack(self.maps)\n",
    "\n",
    "\n",
    "    def stack_maps(self, target, tokenset, syllables):\n",
    "        l = len(target)\n",
    "        cc1, cc2, cc3 = 0,0,0\n",
    "        maps = []\n",
    "        for k in tokenset:\n",
    "            for v in tokenset[k]:\n",
    "                pair = (v, self.target)\n",
    "                case = tu.match_ends(v, target)\n",
    "                shorter = min(pair, key=len)\n",
    "                longer = max(pair, key=len)\n",
    "                diff = len(longer) - len(shorter)\n",
    "\n",
    "\n",
    "                if case.get(\"any\"):\n",
    "                    if diff:\n",
    "                        if case.get(\"first\") and syllables!=1:\n",
    "                            cc1+=1\n",
    "                            wm = tu.wordmap(longer=longer, shorter=shorter)\n",
    "                            while len(wm) < l:\n",
    "                                wm.append(0) # padding\n",
    "                            maps.append(wm)\n",
    "\n",
    "                        if case.get(\"last\"):\n",
    "                            wm = []\n",
    "                            cc2+=1\n",
    "                            wm = tu.wordmap(longer=longer, shorter=shorter, start=diff)\n",
    "                            while len(wm) < l:\n",
    "                                wm.insert(0, 0) # padding\n",
    "                            maps.append(wm)\n",
    "\n",
    "\n",
    "                    else:\n",
    "                        cc3+=1\n",
    "                        wm = tu.wordmap(longer=pair[0], shorter=pair[1])\n",
    "                        maps.append(wm)\n",
    "        print(\"Cases:\", cc1, cc2, cc3)\n",
    "        return maps\n",
    "\n",
    "\n",
    "    def filter_map_noise(self, maps, pattern):\n",
    "        \"\"\"Convert maps to strings and delete any consecutive '1' not at the start or end of the map\"\"\"\n",
    "        str_maps = [\"\".join([str(c) for c in m]) for m in maps]\n",
    "        #for m in maps:\n",
    "        #    mstr = \"\"\n",
    "        #    for i in m:\n",
    "        #        mstr += str(i)\n",
    "        #    str_maps.append(mstr)\n",
    "\n",
    "        recount_map = [rex.sub(pattern=pattern, repl=lambda m: len(m.group(1))*\"0\",string=sm) for sm in str_maps]  # substitute false positives\n",
    "        #for cnt in str_maps:\n",
    "        #    sr = rex.sub(pattern='([^^1][0*1*]+[^$1])', repl=lambda m: len(m.group(1))*\"0\",string=cnt)\n",
    "        #    recount_map.append(sr)\n",
    "\n",
    "        regexed_listed = [list(i) for i in recount_map]\n",
    "        regexed_inted = [[int(c) for c in m] for m in regexed_listed]  # cast back to int\n",
    "\n",
    "        #for i in regexed_listed:\n",
    "        #    regexed_inted.append([int(j) for j in i])\n",
    "\n",
    "        self.clean_maps = regexed_inted\n",
    "\n",
    "    def sum_map_stack(self, maps):\n",
    "        return [sum(x) for x in zip(*maps)]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cases: 10632 10685 385\n"
     ]
    }
   ],
   "source": [
    "wordmap = WordMapper(\"sehen\", pc.counted_corpus, clean=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "[11667, 2440, 5956, 5560, 11199]"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordmap.wordmap"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "'sehen'"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def raw_map(target, maps):\n",
    "    \"\"\"Returns a single map by stacking a list of maps\"\"\"\n",
    "    new_maps = [x for x in maps if len(x)==len(target)]\n",
    "    return [sum(x) for x in zip(*new_maps)]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'WordMap' object has no attribute 'ts'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_26960/3465530523.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mt1\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mWordMap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"sagen\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcounted_corpus\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/tmp/ipykernel_26960/2026951767.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, target, tokenset)\u001B[0m\n\u001B[1;32m      4\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtarget\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtokenset\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtokenset\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmaps\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstack_maps\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtarget\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtokenset\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mts\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtu\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcount_syllables\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtarget\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_26960/2026951767.py\u001B[0m in \u001B[0;36mstack_maps\u001B[0;34m(self, target, tokenset)\u001B[0m\n\u001B[1;32m     23\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mcase\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"any\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     24\u001B[0m                     \u001B[0;32mif\u001B[0m \u001B[0mdiff\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 25\u001B[0;31m                         \u001B[0;32mif\u001B[0m \u001B[0mcase\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"first\"\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mts\u001B[0m\u001B[0;34m!=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     26\u001B[0m                             \u001B[0mcc1\u001B[0m\u001B[0;34m+=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     27\u001B[0m                             \u001B[0mwm\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtu\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwordmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlonger\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlonger\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshorter\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mshorter\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'WordMap' object has no attribute 'ts'"
     ]
    }
   ],
   "source": [
    "class MapToken:\n",
    "    def __init__(self, token, wm=list):\n",
    "        self.wordmap = wm\n",
    "        self.freqmap = map\n",
    "        self.str = token\n",
    "        self.str_list = list(map)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "[1092, 1059, 799, 1646, 7839, 24274]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000001 24413\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "[('000001', 16022),\n ('000011', 6215),\n ('000111', 972),\n ('100011', 473),\n ('100001', 343),\n ('100000', 105),\n ('001111', 89),\n ('110001', 71),\n ('110011', 57),\n ('110000', 33),\n ('011111', 23),\n ('100111', 7),\n ('111100', 1),\n ('111111', 1),\n ('101111', 1)]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections as cl\n",
    "n_maps = cl.Counter(recount_map).most_common(50)\n",
    "n_maps[:50]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##en\n"
     ]
    }
   ],
   "source": [
    "def map_subword(target: str, map:str) -> str:\n",
    "    \"\"\"Returns a subword from a target string and a map. Yet to implement maps with 1 on both ends.\"\"\"\n",
    "    if map.startswith(\"1\"):\n",
    "        return target[:map.count(\"1\")]+\"##\"\n",
    "    elif map.endswith(\"1\"):\n",
    "        return \"##\"+target[-map.count(\"1\"):]\n",
    "print(map_subword(\"verstehen\", \"000000011\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
