{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import text_utilities as tu\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 5010\n",
      "2 27261\n",
      "3 30123\n",
      "4 14810\n",
      "5 4455\n",
      "6 1005\n",
      "7 193\n",
      "8 32\n"
     ]
    }
   ],
   "source": [
    "wordset = tu.from_path('../data/experiment/verbs')\n",
    "\n",
    "verb_dict = tu.count_syllables(wordset)\n",
    "verb_dict.keys()\n",
    "for i in range(1,9): # von mächtigster menge absteigend morpheme analysieren\n",
    "    print(i, len(verb_dict[i]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tokenizer-Vokabular anhand des Token-Vokabulars erstellen:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5036 9195 2755\n"
     ]
    }
   ],
   "source": [
    "\"\"\"mapping 1010101 comparing words left and right\"\"\"\n",
    "maps = []\n",
    "target = \"verstehen\"\n",
    "l = len(target)\n",
    "cnt = 0\n",
    "cc1, cc2, cc3 = 0,0,0\n",
    "\n",
    "for k in verb_dict:\n",
    "    for v in verb_dict[k]:\n",
    "        pair = (v, target)\n",
    "        case = tu.match_ends(v, target)\n",
    "        shorter = min(pair, key=len)\n",
    "        longer = max(pair, key=len)\n",
    "        diff = len(longer) - len(shorter)\n",
    "\n",
    "\n",
    "        if case.get(\"any\"):\n",
    "            cnt+=1\n",
    "            if diff:\n",
    "                if case.get(\"first\"):\n",
    "                    cc1+=1\n",
    "                    m = tu.wordmap(longer=longer, shorter=shorter)\n",
    "                    while len(m) < l:\n",
    "                        m.append(0) # padding\n",
    "                    maps.append(m)\n",
    "\n",
    "                if case.get(\"last\"):\n",
    "                    m = []\n",
    "                    cc2+=1\n",
    "                    m = tu.wordmap(longer=longer, shorter=shorter, start=diff)\n",
    "                    while len(m) < l:\n",
    "                        m.insert(0, 0) # padding\n",
    "                    maps.append(m)\n",
    "\n",
    "\n",
    "            else:\n",
    "                cc3+=1\n",
    "                m = tu.wordmap(longer=pair[0], shorter=pair[1])\n",
    "                maps.append(m)\n",
    "\n",
    "print(cc1, cc2, cc3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "[6323, 7117, 6514, 2775, 1722, 2499, 1106, 5997, 10854]"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summe aller gleichlangen maps untereinander, bildet nur Tendenz ab\n",
    "#itertools recipes\n",
    "new_maps = [x for x in maps if len(x)==len(target)]\n",
    "sum_new_maps = [sum(x) for x in zip(*new_maps)]\n",
    "sum_new_maps"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111000000 16986\n"
     ]
    }
   ],
   "source": [
    "# konvertiere map in string, nur vorübergehend?\n",
    "str_maps = []\n",
    "for m in maps:\n",
    "    mstr = \"\"\n",
    "    for i in m:\n",
    "        mstr += str(i)\n",
    "    str_maps.append(mstr)\n",
    "print(str_maps[0], len(str_maps))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# neue maps ignorieren unterschiede im wortinneren\n",
    "import regex as rex\n",
    "recount_map = []\n",
    "for cnt in str_maps:\n",
    "    sr = rex.sub(pattern='([^^1][0*1*]+[^$1])', repl=lambda m: len(m.group(1))*\"0\",string=cnt)\n",
    "    recount_map.append(sr)\n",
    "\n",
    "# recount_map"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6323, 5573, 5537, 1246, 244, 174, 402, 4578, 10854]\n"
     ]
    }
   ],
   "source": [
    "# word map after\n",
    "regexed_listed = [list(i) for i in recount_map]\n",
    "regexed_inted = []\n",
    "for i in regexed_listed:\n",
    "    regexed_inted.append([int(j) for j in i])\n",
    "\n",
    "new_maps = [x for x in regexed_inted if len(x)==len(target)]\n",
    "sum_new_maps = [sum(x) for x in zip(*new_maps)]\n",
    "\n",
    "print(sum_new_maps)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "[('000000001', 6206),\n ('111000000', 4219),\n ('000000011', 4068),\n ('111100000', 954),\n ('100000000', 714),\n ('000000111', 278),\n ('111110000', 153),\n ('111000011', 81),\n ('000001111', 80),\n ('111111000', 54),\n ('110000000', 34),\n ('000111111', 31),\n ('111100001', 26),\n ('100000001', 26),\n ('111100011', 21),\n ('111000001', 17),\n ('100000011', 8),\n ('111111100', 3),\n ('111001111', 3),\n ('111000111', 2),\n ('110000001', 2),\n ('111111111', 1),\n ('111100111', 1),\n ('111110011', 1),\n ('100001111', 1),\n ('111111110', 1),\n ('100000111', 1)]"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections as cl\n",
    "n_maps = cl.Counter(recount_map).most_common(50)\n",
    "n_maps[:50]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##en\n"
     ]
    }
   ],
   "source": [
    "def map_subword(target: str, map:str) -> str:\n",
    "    \"\"\"Returns a subword from a target string and a map. Yet to implement maps with 1 on both ends.\"\"\"\n",
    "    if map.startswith(\"1\"):\n",
    "        return target[:map.count(\"1\")]+\"##\"\n",
    "    elif map.endswith(\"1\"):\n",
    "        return \"##\"+target[-map.count(\"1\"):]\n",
    "print(map_subword(\"verstehen\", \"000000011\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
